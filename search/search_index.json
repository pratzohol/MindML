{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About Me","text":"<p>I completed my Bachelor's from IIT Delhi in Electrical Engineering. I love statistics, probability and linear algebra. I also love to learn about recent trends in Machine Learning and Artifical Intelligence. Mostly I have worked on GNNs, NLP and Computer Vision. I would also like to explore Theoritical ML in more depth. Also, I like coding and problem solving.</p> <p>I'm also an endurance cyclist and runner. Currently I'm preparing for Half Ironman. I Seriously need to learn how to swim \ud83d\ude2d\ud83d\ude2d. You are welcome to follow my journey on Insta @woofyluffy (I'm a big time One piece fan also!!)</p> <p>In case you found this slightly useful, it's recommended to use the search feature for finding relevant topics/notes quickly.</p>"},{"location":"#what-is-mindml","title":"What is MindML?","text":"<p>Inspired from Notes on AI, MindML is a personal wiki on AI and ML. It is a collection of notes, resources, and ideas on various topics in AI and ML. The search function and simplistic site makes it easy to navigate and revisit the concepts I have learnt.</p> To-Do List <ul> <li> MRR, CodeBERT, ELECTRA  </li> </ul>"},{"location":"_AI/contrastive-learning/","title":"Contrastive Learning","text":""},{"location":"_AI/contrastive-learning/#1-definition","title":"1. Definition","text":"<p>Contrastive learning aims at learning low-dimensional representations of data by contrasting between similar and dissimilar samples.</p> <p>What this means is that it tries to bring similar samples close to each other in the representation space and push dissimilar samples away from each other.</p> <p>Let's suppose we have 3 images, \\(I_1\\), \\(I_2\\) and \\(I_3\\), where \\(I_1\\) and \\(I_2\\) belongs to same class (e.x. dog) and \\(I_3\\) belongs to different class (e.x. cat). The representation space will look something like this:</p> <p></p> <p>We see that the distance \\(d(x_1, x_2)\\) is small compared to \\(d(x_1, x_3)\\) and \\(d(x_2, x_3)\\) where \\(d()\\) is a metric function like euclidean.</p>"},{"location":"_AI/contrastive-learning/#2-loss-functions","title":"2. Loss Functions","text":""},{"location":"_AI/contrastive-learning/#21-contrastive-loss","title":"2.1. Contrastive Loss","text":"<p>We suppose that we have a pair (\\(I_i\\), \\(I_j\\)) and a label \\(Y\\) that is equal to 0 if the samples are similar and 1 otherwise. To extract a low-dimensional representation of each sample, we use a Convolutional Neural Network \\(f\\) that encodes the input images \\(I_i\\) and \\(I_j\\) into an embedding space where \\(x_i = f(I_i)\\) and \\(x_j = f(I_j)\\). The contrastive loss is defined as:  </p> \\[\\mathbf{L = (1-Y) * ||x_i - x_j||^2 + Y * max(0, m - ||x_i - x_j||^2)}\\] <p>where \\(m\\) is a hyperparameter, defining lower bound distance between dissimilar samples. This can be thought of as :  </p> <ul> <li>If \\(Y = 0\\), then samples are similar and hence, we want to minimize the distance between \\(\\mathbf{x_i}\\) and \\(\\mathbf{x_j}\\).  </li> <li>If \\(Y = 1\\), then samples are dissimilar and minimizing \\(\\mathbf{L}\\) means we want to make the term \\(m - ||x_i - x_j||^2\\) \\(\\leq\\) 0. Thus, we want the distance between \\(\\mathbf{x_i}\\) and \\(\\mathbf{x_j}\\) to be maximized and greater than the lower bound \\(m\\).</li> <li>[NOTE :] This is not a classification task. We are trying to learn the embedding \\(\\mathbf{x_i}\\) for the \\(i\\)-th sample.</li> </ul>"},{"location":"_AI/contrastive-learning/#22-triplet-loss","title":"2.2. Triplet Loss","text":"<p>It takes triplet as input : an anchor sample \\(I\\), a positive sample \\(I^{+}\\) and a negative sample \\(I^{-}\\). During training, the loss function enforces the distance between anchor and positive sample to be less than the distance between anchor and negative sample.</p> <p>The triplet loss is defined as:</p> \\[\\mathbf{L = max(0, ||x - x^{+}||^2 - ||x - x^{-}||^2 + m)}\\] <p>where \\(m\\) is a hyperparameter defined in contrastive loss. Here also, we want dissimilar to be far and similar to be close so that the term \\(||x - x^{+}||^2 - ||x - x^{-}||^2 + m\\) \\(\\leq\\) 0.</p>"},{"location":"_AI/contrastive-learning/#3-types-of-learning","title":"3. Types of Learning","text":""},{"location":"_AI/contrastive-learning/#31-self-supervised-learning","title":"3.1. Self-Supervised Learning","text":"<p>When we don't have labeled samples, we use unsupervised learning, also known as self-supervised learning.</p> <p>A famous self-supervised framework for unsupervised contrastive learning is SimCLR. Its main idea is to generate positive image pairs by applying random transformations in the anchor image like crop, flip and color jitter since these changes keep the label of the image unchanged.</p>"},{"location":"_AI/contrastive-learning/#32-supervised-learning","title":"3.2. Supervised Learning","text":"<p>The label of each sample is available during training. So, we can generate positive and negative pairs or triplets by just looking at the labels. </p> <p>Positive Pairs : Samples with same label Negative Pairs : Samples with different label</p> <p>However, generating all possible pairs or triplets requires a lot of time and computational resources. Also, in every dataset, there are many negative pairs or triplets that already satisfy the contrastive training objectives and give zero loss resulting in slow training convergence.</p> <p>To deal with this problem, we have to generate hard pairs and hard triplets, meaning that their loss value is high, i.e., similar pairs that are far apart and dissimilar pairs that are very close. </p> <p>Many hard negative mining methods have been proposed that usually look into the representation space for hard pairs and triplets using fast search algorithms.</p> <pre><code>It only makes sense that this kind of contrastive learning will be used mostly with self-supervised (unsupervised) or semi-supervised settings.\n</code></pre>"},{"location":"_AI/erdos-renyl-model/","title":"Erdos Renyl Model : Generating Random Graphs","text":""},{"location":"_AI/erdos-renyl-model/#1-overview","title":"1. Overview","text":"<ul> <li> <p>There are two variants of Erdos Renyl Model:</p> <ul> <li>G(n, p) : n nodes, each edge is present with probability p</li> <li>G(n, m) : n nodes, m edges are chosen uniformly at random from the set of all possible edges</li> </ul> </li> <li> <p>Equivalently, all graphs with n nodes and M edges have equal probability of \\(p^M (1-p)^{\\binom{n}{2}-M}\\)</p> </li> <li>The parameter p in this model can be thought of as a weighting function; as p increases from 0 to 1, the model becomes more and more likely to include graphs with more edges and less and less likely to include graphs with fewer edges.</li> <li>A graph in G(n, p) has on average \\({\\binom{n}{2}}p\\) edges. </li> <li>The distribution of the degree of any particular vertex is binomial: \\(P(deg(v)=k)=\\binom{n-1}{k}{p^k}(1-p)^{n-1-k}\\) </li> </ul>"},{"location":"_AI/erdos-renyl-model/#2-references","title":"2. References","text":"<ul> <li>https://www.geeksforgeeks.org/erdos-renyl-model-generating-random-graphs/ </li> </ul>"},{"location":"_AI/in-context-learning/","title":"In-context Learning (ICL)","text":""},{"location":"_AI/in-context-learning/#1-definition","title":"1. Definition","text":"<p>In-context Learning or ICL was defined in \"Language Models are few-shot learners\" by Brown et al., the paper that introduced GPT-3. The authors define ICL as:</p> <p>During unsupervised pre-training, a language model develops a broad set of skills and pattern recognition abilities. It then uses these abilities at inference time to rapidly adapt to or recognize the desired task. We use the term \u201cin-context learning\u201d to describe the inner loop of this process, which occurs within the forward-pass upon each sequence.</p>"},{"location":"_AI/in-context-learning/#2-icl-vs-size-of-the-model","title":"2. ICL vs Size of the Model","text":"<p>Aky\u00fcrek et al. make another observation that ICL exhibits algorithmic phase transitions as model depth increases:</p> <ul> <li>One-layer transformers\u2019 ICL behavior approximates a single step of gradient descent, while wider and deeper transformers match ordinary least squares or ridge regression solutions.</li> <li>It is possible to imagine that if small models implement simple learning algorithms in-context, larger models might implement more sophisticated functions during ICL.</li> <li>Smaller models do not seem to learn from in-context examples, and larger ones do.</li> </ul>"},{"location":"_AI/learning-paradigms/","title":"Types of Learning in Machine Learning","text":"<p>There are broadly 3 different types of learning in Machine Learning paradigm:</p> <ul> <li>Supervised Learning</li> <li>Unsupervised Learning</li> <li>Semi-supervised Learning</li> </ul>"},{"location":"_AI/learning-paradigms/#1-supervised-learning","title":"1. Supervised Learning","text":"<p>When we have lots of labeled samples and we want to train our model to learn from these samples, we use Supervised Learning. Model's performance is measure against a test set which is not seen during training. (We have true labels of the test set)</p>"},{"location":"_AI/learning-paradigms/#2-unsupervised-learning","title":"2. Unsupervised Learning","text":"<p>When we don't have any labeled data and instead model tries to discover patterns and insights without any explicit guidance or instruction. For example, clustering is an unsupervised learning task.</p>"},{"location":"_AI/learning-paradigms/#21-self-supervised-learning","title":"2.1. Self-supervised Learning","text":"<ul> <li>This is kinda unsupervised but with an additional supervisory signal.</li> <li>For example, one perform augmentations on the same images and label them as a positive pair, different images as negative pair, and attempts to push the learnt features of negative pairs away while dragging positive features close.</li> <li>Constrastive learning is a type of self-supervised learning.</li> <li>This enables the network to learn to group images of similar classes, which allows model to perform classification / segmentation tasks without having ground truths.</li> </ul>"},{"location":"_AI/learning-paradigms/#3-semi-supervised-learning","title":"3. Semi-supervised Learning","text":"<p>When we have a few labeled samples and a lot of unlabeled samples, we want to be able to use both of them to optimize the performance and learning capability of our model. This is the definition of Semi-supervised Learning.</p>"},{"location":"_AI/mrr/","title":"Mean Reciprocal Rank (MRR)","text":""},{"location":"_AI/Models/codebert/","title":"CodeBERT","text":""},{"location":"_AI/Models/codebert/#1","title":"1.","text":""},{"location":"_AI/Models/electra/","title":"ELECTRA","text":""},{"location":"_AI/Models/electra/#1","title":"1.","text":""},{"location":"_CS/disjoint-set/","title":"Disjoint Set Data Structure","text":""},{"location":"_CS/disjoint-set/#1-introduction","title":"1. Introduction","text":"<p>Disjoint Set Union or DSU is also called Union Find because of its two main operations. The basic interface of this data structure consists of only two operations:</p> <ul> <li><code>find_set(v)</code> - returns the ultimate parent of the set that contains the element <code>v</code>. This can be used to check if two elements are part of the same set or not. <code>a</code> and <code>b</code> are exactly in the same set, if <code>find_set(a) == find_set(b)</code>. Otherwise they are in different sets.</li> <li><code>union_sets(a, b)</code> - merges two sets (the sets in which the element <code>a</code> and element <code>b</code> is located)</li> </ul>"},{"location":"_CS/disjoint-set/#2-implementation","title":"2. Implementation","text":""},{"location":"_CS/disjoint-set/#21-union-by-rank","title":"2.1 Union by rank","text":"<pre><code>class DSU {\npublic:\n    vector&lt;int&gt; parent, rank;\n\n    // Initialize DSU data structure\n    DSU (int n) {\n        parent.resize(n);\n        rank.resize(n, 0);\n\n        for (int i = 0; i &lt; n; ++i) {\n            parent[i] = i;\n        }\n    }\n\n    // find ultimate parent while doing\n    // path compression optimization\n    int find_set(int v) {\n        if (parent[v] != v) {\n            parent[v] = find_set(parent[v]);\n        }\n        return parent[v];\n    }\n\n    // Union by Rank\n    void union_sets(int a, int b) {\n        a = find_set(a);\n        b = find_set(b);\n\n        if (a != b) {\n            if (rank[a] &lt; rank[b])\n                swap(a, b);\n\n            parent[b] = a;\n\n            if (rank[a] == rank[b]) {\n                rank[a]++;\n            }\n        }\n    }\n};\n</code></pre>"},{"location":"_CS/disjoint-set/#22-union-by-size","title":"2.2 Union by size","text":"<pre><code>class DSU {\npublic:\n    vector&lt;int&gt; parent, size;\n\n    // Initialize DSU data structure\n    DSU (int n) {\n        parent.resize(n);\n        size.resize(n, 0);\n\n        for (int i = 0; i &lt; n; ++i) {\n            parent[i] = i;\n        }\n    }\n\n    // find ultimate parent while doing\n    // path compression optimization\n    int find_set(int v) {\n        if (parent[v] != v) {\n            parent[v] = find_set(parent[v]);\n        }\n        return parent[v];\n    }\n\n    // Union by Size\n    void union_sets(int a, int b) {\n        a = find_set(a);\n        b = find_set(b);\n\n        if (a != b) {\n            if (size[a] &lt; size[b])\n                swap(a, b);\n\n            parent[b] = a;\n            size[a] += size[b];\n        }\n    }\n};\n</code></pre>"},{"location":"_CS/disjoint-set/#3-complexity","title":"3. Complexity","text":"<ul> <li>Time Complexity --&gt;  \\(O(1)\\)<ul> <li>If we combine both optimizations - path compression with union by size / rank - we will reach nearly constant time queries.</li> <li>The final amortized time complexity is  \\(O(\\alpha(n))\\) , where  \\(\\alpha(n)\\) \u200ais the inverse Ackermann function, which grows very slowly.</li> <li>It grows so slowly, that it doesn't exceed\u200a \\(4\\)\u200a for all reasonable \\(n\\)\u200a(approximately \u200a\\(n &lt; 10^{600}\\) .</li> <li>If we only use Path compression, the  \\(T(n) = O(\\log n)\\)\u200a  per call on average.</li> </ul> </li> <li>Space Complexity --&gt;  \\(O(n)\\)</li> </ul>"},{"location":"_CS/_Algorithms/bellman-ford/","title":"Bellman Ford Algorithm","text":""},{"location":"_CS/_Algorithms/bellman-ford/#1-problem-statement","title":"1. Problem Statement","text":"<p>Given a graph and a source vertex in the graph, find shortest paths from source to all vertices in the given graph.</p>"},{"location":"_CS/_Algorithms/bellman-ford/#2-solution","title":"2. Solution","text":""},{"location":"_CS/_Algorithms/bellman-ford/#21-when-to-use","title":"2.1 When to use","text":"<ul> <li>Dijkstra's algo fails if graph contains negative edges or negative cycle.</li> <li>Bellman-Ford works well if the graph contains negative edges.</li> <li>It is also able to detect if any negative cycle is present in the graph.</li> <li>Bellman ford works with directed graphs. For undirected graphs, convert it to directed graph first.</li> </ul>"},{"location":"_CS/_Algorithms/bellman-ford/#22-code","title":"2.2 Code","text":"<pre><code>vector&lt;int&gt; bellman_ford(int V, vector&lt;vector&lt;int&gt;&gt;&amp; edges, int src) {\n    vector&lt;int&gt; dist(V, 1e8);\n    dist[src] = 0;\n\n    vector&lt;int&gt; parent(V);\n    for (int i = 0; i &lt; V; i++) {\n        parent[i] = i;\n    }\n\n    // Relaxation of all the edges V times, not (V - 1) as we\n    // need one additional relaxation to detect negative cycle\n    for (int i = 0; i &lt; V; i++) {\n        for (vector&lt;int&gt; edge : edges) {\n            int u = edge[0];\n            int v = edge[1];\n            int wt = edge[2];\n            if (dist[u] != 1e8 &amp;&amp; dist[u] + wt &lt; dist[v]) {\n\n                // If this is the Vth relaxation, then there is\n                // a negative cycle\n                if(i == V - 1)\n                    return {-1};\n\n                // Update shortest distance to node v\n                dist[v] = dist[u] + wt;\n                parent[v] = u;\n            }\n        }\n    }\n\n    return dist;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/bellman-ford/#4-complexity","title":"4. Complexity","text":"<ul> <li>Time Complexity --&gt; \\(O(V*E)\\)</li> <li>Space Complexity --&gt; \\(O(V)\\)</li> </ul>"},{"location":"_CS/_Algorithms/bfs-dfs/","title":"BFS &amp; DFS","text":""},{"location":"_CS/_Algorithms/bfs-dfs/#1-bfs","title":"1. BFS","text":"<pre><code>vector&lt;int&gt; BFS(int V, vector&lt;int&gt; adj[]) {\n    int visited[V] = {0};\n    visited[0] = 1; //start from node 0\n\n    queue&lt;int&gt; q;\n    q.push(0);\n\n    vector&lt;int&gt; bfs_nodes;\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n        bfs.push_back(node);\n\n        for (int nbr : adj[node]) {\n            if (!visited[nbr]) {\n                visited[nbr] = 1;\n                q.push(nbr);\n            }\n        }\n    }\n    return bfs_nodes;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/bfs-dfs/#2-dfs","title":"2. DFS","text":"<p><pre><code>void dfs(int node, vector&lt;int&gt;&amp; adj[], int visited[], vector&lt;int&gt;&amp; dfs_nodes) {\n    visited[node] = 1;\n    dfs_nodes.push_back(node);\n\n    for (int nbr : adj[node]) {\n        if (!visited[nbr]) {\n            dfs (nbr, adj, visited, dfs_nodes);\n        }\n    }\n}\n</code></pre> <pre><code>vector&lt;int&gt; DFS(int V, vector&lt;int&gt; adj[]) {\n    int visited[V] = {0};\n\n    vector&lt;int&gt; dfs_nodes;\n\n    dfs(0, adj, visited, dfs_nodes);\n    return dfs_nodes;\n}\n</code></pre></p>"},{"location":"_CS/_Algorithms/bfs-dfs/#3-complexity","title":"3. Complexity","text":"<ul> <li>Time Complexity -&gt; \\(O(V + E)\\)</li> <li>Space Complexity -&gt; \\(O(V)\\)</li> </ul>"},{"location":"_CS/_Algorithms/dijkstra/","title":"Dijkstra's Algo","text":""},{"location":"_CS/_Algorithms/dijkstra/#1-problem-statement","title":"1. Problem Statement","text":"<p>Given a graph and a source vertex in the graph, find shortest paths from source to all vertices in the given graph.</p> <ul> <li>NOTE : If graph is a DAG, then simply do Topological Sort and store the vertices in a stack. Then pop the vertices from the stack and update the distances of the adjacent vertices.</li> <li>This is because to calculate shortest path of any node, we need to calculate the shortest path of all the nodes that come before it. Thus, this automatically calls for topological sorting.</li> </ul>"},{"location":"_CS/_Algorithms/dijkstra/#2-solution","title":"2. Solution","text":"<ul> <li>NOTE: Dijkstra\u2019s Algorithm is not valid for negative weights or negative cycles.</li> <li>A negative cycle is a cycle whose edges are such that the sum of their weights is a negative value.</li> <li>Difference between using <code>sets</code> and <code>priority_queues</code> is that in <code>sets</code> we can check if there exists a pair with the same node but a greater distance than the current distance.</li> <li>This is not possible in <code>priority_queues</code> as we cannot erase a particular element from the queue. Thus, we need to push the same node with a smaller distance and the <code>priority_queue</code> will automatically sort it.</li> <li>We can use <code>queues</code> also but it will be slower than the above two methods.</li> </ul>"},{"location":"_CS/_Algorithms/dijkstra/#21-using-sets","title":"2.1 Using Sets","text":"<pre><code>vector&lt;int&gt; dijkstra(int V, vector&lt;vector&lt;int&gt;&gt; adj, int src) {\n    // Create a set for storing the nodes as a pair {dist,node}\n    set&lt;pair&lt;int,int&gt;&gt; st;\n\n    // Initialising dist list with a large number to\n    // indicate the nodes are unvisited initially.\n    // This list contains distance from source to the nodes.\n    vector&lt;int&gt; dist(V, 1e9);\n\n    st.insert({0, src});\n\n    // Source initialised with dist=0\n    dist[src] = 0;\n\n    // Now, erase the minimum distance node first from the set\n    // and traverse for all its adjacent nodes.\n    while(!st.empty()) {\n        auto it = *(st.begin());\n\n        int node = it.second;\n        int dis = it.first;\n        st.erase(it);\n\n        // Check for all adjacent nodes of the erased\n        // element whether the prev dist is larger than current or not.\n        for(auto it : adj[node]) {\n            int adjNode = it[0];\n            int edgW = it[1];\n\n            if(dis + edgW &lt; dist[adjNode]) {\n                // erase if it was visited previously at\n                // a greater cost.\n                if(dist[adjNode] != 1e9)\n                    st.erase({dist[adjNode], adjNode});\n\n                // If current distance is smaller,\n                // push it into the queue\n                dist[adjNode] = dis + edgW;\n                st.insert({dist[adjNode], adjNode});\n            }\n        }\n    }\n    return dist;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/dijkstra/#22-using-priority-queues","title":"2.2 Using Priority Queues","text":"<pre><code>vector&lt;int&gt; dijkstra(int V, vector&lt;vector&lt;int&gt;&gt; adj, int S) {\n    // Create a p.q. for storing the nodes as a pair {dist,node}\n    priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; pq;\n\n    // This list contains distance from source to the nodes.\n    vector&lt;int&gt; distTo(V, INT_MAX);\n\n    // Source initialised with dist=0.\n    distTo[S] = 0;\n    pq.push({0, S});\n\n    // Now, pop the minimum distance node first from the min-heap\n    // and traverse for all its adjacent nodes.\n    while (!pq.empty()) {\n        int node = pq.top().second;\n        int dis = pq.top().first;\n        pq.pop();\n\n        // Check for all adjacent nodes of the popped out\n        // element whether the prev dist is larger than current or not.\n        for (auto it : adj[node]) {\n            int v = it[0];\n            int w = it[1];\n\n            if (dis + w &lt; distTo[v]) {\n                distTo[v] = dis + w;\n\n                // If current distance is smaller,\n                // push it into the queue.\n                pq.push({dis + w, v});\n            }\n        }\n    }\n    return distTo;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/dijkstra/#3-complexity","title":"3. Complexity","text":"<ul> <li>Time Complexity --&gt; \\(O(E*logV)\\) if using sets, else \\(O(E*logE)\\) if using min-heap</li> <li>Space Complexity --&gt; \\(O(V)\\)</li> </ul>"},{"location":"_CS/_Algorithms/floyd-warshall/","title":"Floyd Warshall Algo","text":""},{"location":"_CS/_Algorithms/floyd-warshall/#1-problem-statement","title":"1. Problem Statement","text":"<p>Given a graph and a source vertex in the graph, find shortest paths between all pair of vertices in the given graph.</p>"},{"location":"_CS/_Algorithms/floyd-warshall/#2-solution","title":"2. Solution","text":""},{"location":"_CS/_Algorithms/floyd-warshall/#21-when-to-use","title":"2.1 When to use","text":"<ul> <li>Works for both directed and undirected weighted graphs and can handle negative weight edges.</li> <li>Does not work for the graphs with negative cycles.</li> <li>Can detect neagtive cycles just like Bellman Ford Algo</li> </ul>"},{"location":"_CS/_Algorithms/floyd-warshall/#22-code","title":"2.2 Code","text":"<ul> <li>We assume if there is no edge between <code>i</code> and <code>j</code>, then <code>matrix[i][j] = 1e8</code> and <code>matrix[i][i] = 0</code>.</li> </ul> <pre><code>void floyd_warshall(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {\n    int n = matrix.size();\n\n    for (int k = 0; k &lt; n; k++) {\n        for (int i = 0; i &lt; n; i++) {\n            for (int j = 0; j &lt; n; j++) {\n                matrix[i][j] = min(matrix[i][j], matrix[i][k] + matrix[k][j]);\n            }\n        }\n    }\n\n    // To check for negative cycles,\n    // if matrix[i][i] is negative then there is a negative cycle present\n    for (int i = 0; i &lt; n; i++) {\n        if (matrix[i][i] &lt; 0) {\n            cout &lt;&lt; \"Negative cycle found\" &lt;&lt; endl;\n        }\n    }\n}\n</code></pre>"},{"location":"_CS/_Algorithms/floyd-warshall/#4-complexity","title":"4. Complexity","text":"<ul> <li>Time Complexity --&gt; \\(O(V^3)\\)</li> <li>Space Complexity --&gt; \\(O(1)\\)</li> </ul>"},{"location":"_CS/_Algorithms/kadane-algo/","title":"Kadane's Algorithm","text":""},{"location":"_CS/_Algorithms/kadane-algo/#problem","title":"Problem","text":"<p>Given an integer array <code>nums</code>, find the subarray with the largest sum, and return its sum. (Detailed solution)</p>"},{"location":"_CS/_Algorithms/kadane-algo/#algorithm","title":"Algorithm","text":"<ul> <li><code>curr_sum</code> will store the maximum subarray sum ending at i.</li> <li><code>max_sum</code> stores the maximum sum we have seen till now.</li> <li>If <code>curr_sum</code> is negative, then there is no need to include it and we can just take <code>nums[i]</code>, otherwise we add <code>nums[i]</code> to the <code>curr_sum</code>.</li> <li>At each step, we take max of <code>curr_sum</code> and <code>max_sum</code> to store the maximum subarray sum we have seen till now.</li> </ul>"},{"location":"_CS/_Algorithms/kadane-algo/#code","title":"Code","text":"<ul> <li>Time Complexity = \\(O(N)\\)</li> <li>Space Complexity = \\(O(1)\\)</li> </ul> <pre><code>int maxSubArray(vector&lt;int&gt;&amp; nums) {\n    int max_sum = -1e5;\n    int curr_sum = 0;\n\n    for (int i = 0; i &lt; nums.size(); i++) {\n        curr_sum = max(nums[i], nums[i] + curr_sum);\n        max_sum = max(max_sum, curr_sum);\n    }\n\n    return max_sum;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/kosaraju-algo/","title":"Kosaraju's Algorithm","text":""},{"location":"_CS/_Algorithms/kosaraju-algo/#1-problem-statement","title":"1. Problem Statement","text":"<p>Find Strongly Connected Components (SCCs) in a directed graph.</p>"},{"location":"_CS/_Algorithms/kosaraju-algo/#11-strongly-connected-components-sccs","title":"1.1 Strongly Connected Components (SCCs)","text":"<p>In a directed graph, a Strongly Connected Component is a subset of vertices where every vertex is reachable from each other.</p>"},{"location":"_CS/_Algorithms/kosaraju-algo/#2-solution","title":"2. Solution","text":"<pre><code>vector&lt;vector&lt;int&gt;&gt; kosaraju_scc(int V, vector&lt;vector&lt;int&gt;&gt; adj) {\n    vector&lt;int&gt; vis(V, 0);\n    stack&lt;int&gt; st;\n    for (int i = 0; i &lt; V; i++) {\n        if (!vis[i]) {\n            dfs(i, vis, adj, st);\n        }\n    }\n\n    vector&lt;vector&lt;int&gt;&gt; adjT(V, vector&lt;int&gt;());\n    for (int i = 0; i &lt; V; i++) {\n        vis[i] = 0;\n        for (auto it : adj[i]) {\n            adjT[it].push_back(i);\n        }\n    }\n\n    vector&lt;vector&lt;int&gt;&gt; scc;\n    while (!st.empty()) {\n        int node = st.top();\n        st.pop();\n        if (!vis[node]) {\n            vector&lt;int&gt; scc_i;\n            dfs3(node, vis, adjT, scc_i);\n            scc.push_back(scc_i);\n        }\n    }\n    return scc;\n}\n\nvoid dfs(int node, vector&lt;int&gt; &amp;vis, vector&lt;vector&lt;int&gt;&gt;&amp; adj, stack&lt;int&gt; &amp;st) {\n    vis[node] = 1;\n    for (auto it : adj[node]) {\n        if (!vis[it]) {\n            dfs(it, vis, adj, st);\n        }\n    }\n    st.push(node);\n}\n\nvoid dfs3(int node, vector&lt;int&gt; &amp;vis, vector&lt;vector&lt;int&gt;&gt;&amp; adjT, vector&lt;int&gt;&amp; scc_i) {\n        vis[node] = 1;\n        scc_i.push_back(node);\n\n        for (auto it : adjT[node]) {\n            if (!vis[it]) {\n                dfs3(it, vis, adjT, scc_i);\n            }\n        }\n    }\n</code></pre>"},{"location":"_CS/_Algorithms/kosaraju-algo/#4-complexity","title":"4. Complexity","text":"<ul> <li>Time Complexity --&gt; \\(O(V + E)\\)</li> <li>Space Complexity --&gt; \\(O(V + E)\\)</li> </ul>"},{"location":"_CS/_Algorithms/kruskal-algo/","title":"Kruskal's Algo (MST)","text":""},{"location":"_CS/_Algorithms/kruskal-algo/#1-problem-statement","title":"1. Problem Statement","text":"<p>Given a weighted, undirected, and connected graph of V vertices and E edges. Find the sum of weights of the edges of the Minimum Spanning Tree.</p>"},{"location":"_CS/_Algorithms/kruskal-algo/#11-what-is-mst","title":"1.1 What is MST ?","text":"<p>A Spanning tree is tree-like subgraph consisting of all the vertices in graph. There could be multiple spanning trees. The spanning tree with edges having minimum sum of weights is considered MST.</p>"},{"location":"_CS/_Algorithms/kruskal-algo/#2-solution","title":"2. Solution","text":"<ul> <li>We need to use DSU data structure to check whether two nodes are in the same path or not.</li> </ul> <pre><code>int spanningTree(int V, vector&lt;vector&lt;int&gt;&gt;&amp; adj){\n\n        vector&lt;vector&lt;int&gt;&gt; edges;\n        for (int i = 0; i &lt; V; i++) {\n            for (auto it : adj[i]) {\n                int nbr = it[0];\n                int wt = it[1];\n                int node = i;\n\n                edges.push_back({wt, node, nbr});\n            }\n        }\n        sort(edges.begin(), edges.end());\n\n        DSU dsu(V);\n\n        //mst sum\n        int sum = 0;\n        for (auto it : edges) {\n            int wt = it[0]\n            int u = it[1];\n            int v = it[2];\n\n            if (dsu.find_set(u) != dsu.find_set(v)) {\n                // To store MST edges\n                // just add (u, v) to a vector\n                sum += wt;\n                dsu.union_sets(u, v);\n            }\n        }\n\n        return sum;\n    }\n</code></pre>"},{"location":"_CS/_Algorithms/kruskal-algo/#4-complexity","title":"4. Complexity","text":"<ul> <li>Time Complexity --&gt; \\(O(E \\log E)\\)</li> <li>Space Complexity --&gt; \\(O(E + V)\\)</li> </ul>"},{"location":"_CS/_Algorithms/moore-voting/","title":"Moore's Voting Algorithm","text":""},{"location":"_CS/_Algorithms/moore-voting/#problem","title":"Problem","text":"<p>To find the majority element in an array. Majority element is the one which appear more than \\(\\lfloor n / 2 \\rfloor\\) times in an array.</p>"},{"location":"_CS/_Algorithms/moore-voting/#algorithm","title":"Algorithm","text":"<ul> <li>If the majority element is <code>x</code> then, <code>count(x) - count(any other element) &gt; 0</code>.</li> <li>Assign <code>count = 0</code> and <code>candidate</code> which keeps track of majority element.</li> <li>Run a loop through array, if we face same element as <code>candidate</code>, increase <code>count</code> by 1.</li> <li>Else, decrease the <code>count</code> by 1. </li> <li>If <code>count</code> becomes 0, update <code>candidate</code> by current element.</li> </ul>"},{"location":"_CS/_Algorithms/moore-voting/#code","title":"Code","text":"<ul> <li>Time Complexity = \\(O(N)\\) </li> <li>Space Complexity = \\(O(1)\\)</li> </ul> <pre><code>int majorityElement(vector&lt;int&gt;&amp; nums) {\n    int n = nums.size();\n    int count = 0, candidate = 0;\n\n    for (int i = 0; i &lt; n; i++) {\n        if (count == 0) candidate = nums[i];\n        if (nums[i] == candidate) {\n            count++;\n        }\n        else {\n            count--;\n        }\n    }\n\n    return candidate;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/morris-traversal/","title":"Morris Traversal of Tree","text":""},{"location":"_CS/_Algorithms/morris-traversal/#problem","title":"Problem","text":"<p>Print in-order, pre-order and post-order traversal of tree in \\(O(N)\\) time and \\(O(1)\\) space constraints without using any data structures such as stacks or queues.</p>"},{"location":"_CS/_Algorithms/morris-traversal/#algorithm","title":"Algorithm","text":""},{"location":"_CS/_Algorithms/morris-traversal/#in-order","title":"In-order","text":"<ul> <li>If there is no left subtree, then we just push <code>root-&gt;val</code> to result and move to right (<code>root = root-&gt;right</code>)</li> <li>Otherwise, we find the inorder predecessor, let's say <code>prev</code> of <code>root</code> (This is the value which will pe pushed just before <code>root-&gt;val</code>)</li> <li>We notice that this value will be the rightmost child of left subtree</li> <li>Now, we need to maintain a link from inorder predecessor to the <code>root</code> node</li> <li>So, we assign <code>root</code> as right child of inorder predecessor (<code>prev-&gt;right = root</code>)</li> <li>Now, when we have processed the left subtree, we will find that the <code>prev-&gt;right != nullptr</code>. </li> <li>In that case, we need to push <code>root-&gt;val</code> to result and remove the connection, i.e., <code>prev-&gt;right = nullptr</code> and move the <code>root</code> to right subtree.</li> </ul>"},{"location":"_CS/_Algorithms/morris-traversal/#pre-order","title":"Pre-order","text":"<ul> <li>If there is no left subtree, then we just push <code>root-&gt;val</code> to result and move to right (<code>root = root-&gt;right</code>)</li> <li>Otherwise, we find the inorder predecessor, let's say <code>prev</code> of <code>root</code> (This is the value after which right subtree will pe printed)</li> <li>We notice that this value will be the rightmost child of left subtree</li> <li>Now, we need to maintain a link from inorder predecessor to the <code>root</code> node</li> <li>So, we assign <code>root</code> as right child of inorder predecessor (<code>prev-&gt;right = root</code>) and push <code>root-&gt;val</code> to result.</li> <li>Now, when we have processed the left subtree, we will find that the <code>prev-&gt;right != nullptr</code>. </li> <li>In that case, we need to remove the connection, i.e., <code>prev-&gt;right = nullptr</code> and move the <code>root</code> to right subtree.</li> </ul>"},{"location":"_CS/_Algorithms/morris-traversal/#post-order","title":"Post-order","text":"<ul> <li>Post-order is <code>Left -&gt; Right -&gt; Root</code> which is reverse of Pre-order and switching left and right links.</li> <li>So, algorithm is same as Pre-order, instead we find leftmost chuld of right subtree as predecessor.</li> <li>And, instead of assigning right child, we assign left child.</li> </ul>"},{"location":"_CS/_Algorithms/morris-traversal/#code","title":"Code","text":""},{"location":"_CS/_Algorithms/morris-traversal/#in-order_1","title":"In-order","text":"<pre><code>vector&lt;int&gt; preOrder(Node* root) { \n    vector&lt;int&gt; res;\n\n    while (root)  { \n        // If left child is null, print the prev node val. Move to right child. \n        if (root-&gt;left == nullptr)  { \n            res.push_back(root-&gt;val);\n            root = root-&gt;right; \n        } \n        else { \n            // Find inorder predecessor \n            Node* prev = root-&gt;left; \n            while (prev-&gt;right &amp;&amp; prev-&gt;right != root) \n                prev = prev-&gt;right; \n\n            // If the right child of inorder predecessor already points to this node then print this node\n            if (prev-&gt;right == root)  { \n                prev-&gt;right = nullptr; \n                res.push_back(root-&gt;val);\n                root = root-&gt;right; \n            } \n\n            // If right child doesn't point to this node, make right child point to this node \n            else { \n                prev-&gt;right = root; \n                root = root-&gt;left; \n            } \n        } \n    } \n\n    return res;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/morris-traversal/#pre-order_1","title":"Pre-order","text":"<pre><code>vector&lt;int&gt; preOrder(Node* root) { \n    vector&lt;int&gt; res;\n\n    while (root)  { \n        // If left child is null, print the prev node val. Move to  right child. \n        if (root-&gt;left == nullptr)  { \n            res.push_back(root-&gt;val);\n            root = root-&gt;right; \n        } \n        else { \n            // Find inorder predecessor \n            Node* prev = root-&gt;left; \n            while (prev-&gt;right &amp;&amp; prev-&gt;right != root) \n                prev = prev-&gt;right; \n\n            // If the right child of inorder predecessor already points to this node \n            if (prev-&gt;right == root)  { \n                prev-&gt;right = nullptr; \n                root = root-&gt;right; \n            } \n\n            // If right child doesn't point to this node, then print this node and make right child point to this node \n            else { \n                res.push_back(root-&gt;val);\n                prev-&gt;right = root; \n                root = root-&gt;left; \n            } \n        } \n    } \n\n    return res;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/morris-traversal/#post-order_1","title":"Post-order","text":"<pre><code>vector&lt;int&gt; postOrder(Node* root) { \n    vector&lt;int&gt; res;\n\n    while (root)  { \n        // If left child is null, print the prev node val. Move to left child. \n        if (root-&gt;right == nullptr)  { \n            res.push_back(root-&gt;val);\n            root = root-&gt;left; \n        } \n        else { \n            // Find predecessor \n            Node* prev = root-&gt;right; \n            while (prev-&gt;left &amp;&amp; prev-&gt;left != root) \n                prev = prev-&gt;left; \n\n            // If the left child of predecessor already points to this node \n            if (prev-&gt;left == root)  { \n                prev-&gt;left = nullptr; \n                root = root-&gt;left; \n            } \n\n            // If left child doesn't point to this node, then print this node and make left child point to this node \n            else { \n                res.push_back(root-&gt;val);\n                prev-&gt;left = root; \n                root = root-&gt;right; \n            } \n        } \n    } \n\n    // reversing the list to get correct post-order nodes\n    reverse(res.begin(), res.end());\n    return res;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/morris-traversal/#complexity","title":"Complexity","text":"<p>Each node will be visited maximum of two times, once to find the inorder predecessor, and next time when the connection between <code>prev</code> and <code>root</code> is already established. So, T = \\(O(2N)\\)</p>"},{"location":"_CS/_Algorithms/prims-algo/","title":"Prim's Algo (MST)","text":""},{"location":"_CS/_Algorithms/prims-algo/#1-problem-statement","title":"1. Problem Statement","text":"<p>Given a weighted, undirected, and connected graph of V vertices and E edges. Find the sum of weights of the edges of the Minimum Spanning Tree.</p>"},{"location":"_CS/_Algorithms/prims-algo/#11-what-is-mst","title":"1.1 What is MST ?","text":"<p>A Spanning tree is tree-like subgraph consisting of all the vertices in graph. There could be multiple spanning trees. The spanning tree with edges having minimum sum of weights is considered MST.</p>"},{"location":"_CS/_Algorithms/prims-algo/#2-solution","title":"2. Solution","text":"<pre><code>vector&lt;vector&lt;int&gt;&gt; prim_mst(int V, vector&lt;vector&lt;int&gt;&gt;&amp; adj){\n    // triplets of {edge weight, node, parent}\n    // if you just want to find the sum, use pair&lt;int, int&gt;\n    priority_queue&lt;vector&lt;int&gt;, vector&lt;vector&lt;int&gt;&gt;, greater&lt;vector&lt;int&gt;&gt;&gt; pq;\n    pq.push({0, 0, -1});\n\n    vector&lt;int&gt; vis(V, 0);\n\n    // stores min sum of MST\n    int sum = 0;\n    // edges of MST in form of {u, v, wt}\n    vector&lt;vector&lt;int&gt;&gt; ans;\n\n    while (!pq.empty()) {\n        auto it = pq.top();\n        pq.pop();\n\n        int wt = it[0];\n        int node = it[1];\n        int parent = it[2];\n\n        if (vis[node] == 1) continue;\n\n        // add it to the mst\n        vis[node] = 1;\n        sum += wt;\n        if (parent != -1) {\n            ans.push_back({node, parent, wt});\n        }\n\n        for (auto it : adj[node]) {\n            int nbr = it[0];\n            int w = it[1];\n            if (!vis[nbr]) {\n                pq.push({w, nbr, node});\n            }\n        }\n    }\n\n    // returns edges of MST\n    return ans;\n}\n</code></pre>"},{"location":"_CS/_Algorithms/prims-algo/#4-complexity","title":"4. Complexity","text":"<ul> <li>Time Complexity --&gt; \\(O(E \\log E)\\)</li> <li>Space Complexity --&gt; \\(O(E + V)\\)</li> </ul>"},{"location":"_CS/_Algorithms/sorting-methods/","title":"Sorting Methods","text":""},{"location":"_CS/_Algorithms/sorting-methods/#1-selection-sort","title":"1. Selection Sort","text":"<pre><code>void selectionSort(int arr[], int n) {\n    for (int i = 0; i &lt; n - 1; i++) {\n        int minIndex = i;\n        for (int j = i + 1; j &lt; n; j++) {\n            if (arr[j] &lt; arr[minIndex]) {\n                minIndex = j;\n            }\n        }\n        swap(arr[i], arr[minIndex]);\n    }\n}\n</code></pre> <ul> <li>Time Complexity -&gt; \\(O(n^2)\\)</li> <li>Space Complexity -&gt; \\(O(1)\\)</li> </ul>"},{"location":"_CS/_Algorithms/sorting-methods/#2-bubble-sort","title":"2. Bubble Sort","text":"<pre><code>void bubbleSort(int arr[], int n) {\n    for (int i = 0; i &lt; n - 1; i++) {\n        for (int j = 0; j &lt; n - i - 1; j++) {\n            if (arr[j] &gt; arr[j + 1]) {\n                swap(arr[j], arr[j + 1]);\n            }\n        }\n    }\n}\n</code></pre> <ul> <li>Time Complexity -&gt; \\(O(n^2)\\)</li> <li>Space Complexity -&gt; \\(O(1)\\)</li> </ul>"},{"location":"_CS/_Algorithms/sorting-methods/#3-insertion-sort","title":"3. Insertion Sort","text":"<pre><code>void insertionSort(int arr[], int n) {\n    for (int i = 1; i &lt; n; i++) {\n        int key = arr[i];\n        int j = i - 1;\n        while (j &gt;= 0 &amp;&amp; arr[j] &gt; key) {\n            arr[j + 1] = arr[j];\n            j--;\n        }\n        arr[j + 1] = key;\n    }\n}\n</code></pre> <ul> <li>Time Complexity -&gt; \\(O(n^2)\\)</li> <li>Space Complexity -&gt; \\(O(1)\\)</li> </ul>"},{"location":"_CS/_Algorithms/sorting-methods/#4-merge-sort","title":"4. Merge Sort","text":"<pre><code>void merge(vector&lt;int&gt; &amp;arr, int low, int mid, int high) {\n    vector&lt;int&gt; temp; \n    int left = low;      \n    int right = mid + 1;  \n\n    while (left &lt;= mid &amp;&amp; right &lt;= high) {\n        if (arr[left] &lt;= arr[right]) {\n            temp.push_back(arr[left]);\n            left++;\n        }\n        else {\n            temp.push_back(arr[right]);\n            right++;\n        }\n    }\n\n    while (left &lt;= mid) {\n        temp.push_back(arr[left]);\n        left++;\n    }\n\n    while (right &lt;= high) {\n        temp.push_back(arr[right]);\n        right++;\n    }\n\n    for (int i = low; i &lt;= high; i++) {\n        arr[i] = temp[i - low];\n    }\n}\n</code></pre> <pre><code>void mergeSort(vector&lt;int&gt; &amp;arr, int low, int high) {\n    if (low &gt;= high) return;\n    int mid = (low + high) / 2 ;\n    mergeSort(arr, low, mid);  \n    mergeSort(arr, mid + 1, high); \n    merge(arr, low, mid, high); \n}\n</code></pre> <ul> <li>Time Complexity -&gt; \\(O(n*logn)\\) </li> <li>Space Complexity -&gt; \\(O(n)\\)</li> <li>Can be done in O(1) space complexity</li> </ul>"},{"location":"_CS/_Algorithms/sorting-methods/#5-quick-sort","title":"5. Quick Sort","text":"<p><pre><code>int partition(vector&lt;int&gt; &amp;arr, int low, int high) {\n    int pivot = arr[low];\n    int i = low;\n    int j = high;\n\n    while (i &lt; j) {\n        while (arr[i] &lt;= pivot &amp;&amp; i &lt;= high - 1) {\n            i++;\n        }\n\n        while (arr[j] &gt; pivot &amp;&amp; j &gt;= low + 1) {\n            j--;\n        }\n        if (i &lt; j) swap(arr[i], arr[j]);\n    }\n    swap(arr[low], arr[j]);\n    return j;\n}\n</code></pre> <pre><code>void qs(vector&lt;int&gt; &amp;arr, int low, int high) {\n    if (low &lt; high) {\n        int pIndex = partition(arr, low, high);\n        qs(arr, low, pIndex - 1);\n        qs(arr, pIndex + 1, high);\n    }\n}\n</code></pre> <pre><code>vector&lt;int&gt; quickSort(vector&lt;int&gt; arr) {\n    qs(arr, 0, arr.size() - 1);\n    return arr;\n}\n</code></pre></p> <ul> <li>Avg. Time Complexity -&gt; \\(O(n*logn)\\)</li> <li>Worst Time Complexity -&gt; \\(O(n^2)\\) </li> <li>Space Complexity -&gt; \\(O(1)\\)</li> <li>Auxiliary Space Complexity -&gt; \\(O(n)\\) (for recursive calls on stack) (on avg., it will be \\(O(logn)\\) but in worst case it will be \\(O(n)\\))</li> </ul>"},{"location":"_CS/_Algorithms/topo-sort/","title":"Topological Sort","text":""},{"location":"_CS/_Algorithms/topo-sort/#1-definition","title":"1. Definition","text":"<ul> <li>In topological sorting, node <code>u</code> will always appear before node <code>v</code> if there is a directed edge from node <code>u</code> towards node <code>v</code>, i.e., <code>u</code> -&gt; <code>v</code>.</li> <li>This is only possible for Directed Acyclic Graphs (DAGs).</li> </ul>"},{"location":"_CS/_Algorithms/topo-sort/#using-dfs","title":"Using DFS","text":"<pre><code>void dfs(int node, int vis[], stack&lt;int&gt; &amp;st, vector&lt;int&gt; adj[]) {\n    vis[node] = 1;\n    for (auto it : adj[node]) {\n        if (!vis[it]) dfs(it, vis, st, adj);\n    }\n    st.push(node);\n}\n\nvector&lt;int&gt; topoSort(int V, vector&lt;int&gt; adj[]) {\n    int vis[V] = {0};\n    stack&lt;int&gt; st;\n\n    for (int i = 0; i &lt; V; i++) {\n        if (!vis[i]) {\n            dfs(i, vis, st, adj);\n        }\n    }\n\n    vector&lt;int&gt; ans;\n    while (!st.empty()) {\n        ans.push_back(st.top());\n        st.pop();\n    }\n    return ans;\n}\n</code></pre> <ul> <li>This Algorithm assumes that graph is DAG.</li> </ul>"},{"location":"_CS/_Algorithms/topo-sort/#using-bfs-kahns-algorithm","title":"Using BFS (Kahn's Algorithm)","text":"<pre><code>vector&lt;int&gt; findOrder(int n, vector&lt;vector&lt;int&gt;&gt;&amp; adj) {\n    vector&lt;int&gt; indegree(n, 0);\n\n    for (int i = 0; i &lt; n; i++) {\n        for (int j : adj[i]) {\n            indegree[j]++;\n        }\n    }\n\n    queue&lt;int&gt; q;\n    for (int i = 0; i &lt; n; i++) {\n        if (indegree[i] == 0) q.push(i);\n    }\n\n    vector&lt;int&gt; ans;\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n        ans.push_back(node);\n\n        for (int nbr : adj[node]) {\n            if (--indegree[nbr] == 0) {\n                q.push(nbr);\n            }\n        }\n    }\n\n    return (ans.size() == n) ? ans : vector&lt;int&gt;(); //check if there's a cycle\n}\n</code></pre>"}]}