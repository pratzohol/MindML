{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>I'm a Fourth year Undergraduate at IIT Delhi majoring in Electrical Engineering. My core interests are in Machine Learning, Deep Learning, and Artificial Intelligence. In addition to these, I enjoy new technology, problem-solving and playing outdoor sports.</p>"},{"location":"#what-is-mindml","title":"What is MindML?","text":"<p>Inspired from Notes on AI, MindML is a personal wiki on AI and ML. It is a collection of notes, resources, and ideas on various topics in AI and ML. The search function and simplistic site makes it easy to navigate and revisit the concepts I have learnt.</p>"},{"location":"#why-mindml","title":"Why MindML?","text":"<p>First of all, I was bored. Second, the concepts, papers and articles I read were all lost and forgotten after few weeks. If I wanted to remember it, I had to again go through the cumbersome task of reading from various sources. </p> <p>Hence, it's better to organize everything in one place. This will also help me in revising the concepts and ideas I have learnt.</p>"},{"location":"#how-i-use-mindml","title":"How I use MindML?","text":"<p>To use MindML, I want myself to go through the pain of reading various articles only once. After that, I want to organize the concepts in my own words and in a way that I can easily understand.</p>"},{"location":"Notes/Definitions/","title":"Definitions","text":"","tags":["Basics"]},{"location":"Notes/Definitions/#1-overview","title":"1. Overview","text":"<p>This post will contain definition of various terms that I come across while reading papers and articles. I will try to keep it updated as I learn more about new terms.</p> <p>These terms are not that complex and time consuming to understand and hence, does not deserve separate posts. So, I will keep on adding them here.</p>","tags":["Basics"]},{"location":"Notes/Definitions/#2-glossary","title":"2. Glossary","text":"","tags":["Basics"]},{"location":"Notes/Definitions/#ccs-concepts","title":"CCS Concepts","text":"<p>\"CCS Concepts\" typically refers to the concepts or topics within the field of computer science that are relevant to the research presented in the paper. CCS stands for \"ACM Computing Classification System,\" which is a standardized classification system used in the computer science community to categorize research papers and topics.</p>","tags":["Basics"]},{"location":"Notes/Definitions/#_1","title":"Definitions","text":"","tags":["Basics"]},{"location":"Notes/Graph_Neural_Networks/icl-over-graphs-GraphPrompt/","title":"ICL over Graphs : GraphPrompt","text":"<p>In this note, I will cover the following paper \"GraphPrompt : Unifying Pre-Training and Downstream Tasks for GNN\".</p> <p>NOTE : Definition of In-context Learning (ICL) is already covered.</p>","tags":["Prompting","ICL","Graphs"]},{"location":"Notes/Graph_Neural_Networks/icl-over-graphs-GraphPrompt/#1","title":"1.","text":"","tags":["Prompting","ICL","Graphs"]},{"location":"Notes/Graph_Neural_Networks/icl-over-graphs-PRODIGY/","title":"ICL over Graphs : PRODIGY","text":"<p>In this note, I will cover the following paper \"PRODIGY : Enabling in-context learning over graphs\".</p> <p>NOTE : Definition of In-context Learning (ICL) is already covered.</p>","tags":["Prompting","ICL","Graphs"]},{"location":"Notes/Graph_Neural_Networks/icl-over-graphs-PRODIGY/#1-introduction","title":"1. Introduction","text":"<p>We can easily infer that the in-context learning is a novel and one of the most intriguing capabilities of language models. However, how to enable in-context learning over graphs is still an unexplored question.</p> <p>An in-context learner for graphs should be able to solve novel tasks on novel graphs. For example, give music product recommendations on Spotify when being trained on Amazon purchasing graph. </p>","tags":["Prompting","ICL","Graphs"]},{"location":"Notes/Graph_Neural_Networks/icl-over-graphs-PRODIGY/#2-challenges","title":"2. Challenges","text":"<ol> <li>How to formulate and represent node-, edge- and graph-level tasks over graphs with a unified task representation that allows the model to solve diverse tasks without the need for retraining or parameter tuning.</li> <li>How to design model architecture and pre-training objectives that enable in-context learning capabilities across diverse tasks and diverse graphs in the unified task representation.</li> <li>Existing graph pre-training methods only aim to learn good graph encoder and require fine-tuning to adapt to different tasks, while existing meta-learning methods over graphs only aim to generalize across tasks within same graph.</li> </ol> <pre><code>Achieving in-context learning requires generalizing across different graphs and\ntasks without fine-tuning or parameter tuning.\n</code></pre>","tags":["Prompting","ICL","Graphs"]},{"location":"Notes/Graph_Neural_Networks/icl-over-graphs-PRODIGY/#3","title":"3.","text":"","tags":["Prompting","ICL","Graphs"]},{"location":"Notes/Miscellaneous/","title":"Miscellaneous","text":""},{"location":"Notes/Miscellaneous/#1-overview","title":"1. Overview","text":"<p>This section will contain miscellaneous  notes that doesn't come under the umbrella topics of other sections like Deep Learning, Graph Neural Networks, etc.</p>"},{"location":"Notes/Miscellaneous/#2-structure","title":"2. Structure","text":"<p>Some of the broad topics which will go into this section are:</p> <ul> <li>Classical ML like SVM, kNN, etc.</li> <li>Concepts from statistics, information theory </li> <li>Probability Concepts</li> <li>Calculus</li> </ul> <p>Further, this section can contain sub-sections. For example, if on a particular topic like SVM, I have a few notes, then I can create a sub-section for it.</p>"},{"location":"Notes/Miscellaneous/#3-tags","title":"3. Tags","text":"<p>I will make a list of tags which were used for this section. Whatever thing I had in my mind, I can easily look up the tags to check whether I already covered it or not.</p> <p>Following are the tags which were used in this section:</p> <ul> <li>Basics</li> <li>ICL</li> </ul>"},{"location":"Notes/Miscellaneous/contrastive-learning/","title":"Contrastive Learning","text":""},{"location":"Notes/Miscellaneous/contrastive-learning/#1-definition","title":"1. Definition","text":"<p>Contrastive learning aims at learning low-dimensional representations of data by contrasting between similar and dissimilar samples.</p> <p>What this means is that it tries to bring similar samples close to each other in the representation space and push dissimilar samples away from each other.</p> <p>Let's suppose we have 3 images, \\(I_1\\), \\(I_2\\) and \\(I_3\\), where \\(I_1\\) and \\(I_2\\) belongs to same class (e.x. dog) and \\(I_3\\) belongs to different class (e.x. cat). The representation space will look something like this:</p> <p></p> <p>We see that the distance \\(d(x_1, x_2)\\) is small compared to \\(d(x_1, x_3)\\) and \\(d(x_2, x_3)\\) where \\(d()\\) is a metric function like euclidean.</p>"},{"location":"Notes/Miscellaneous/contrastive-learning/#2-loss-functions","title":"2. Loss Functions","text":""},{"location":"Notes/Miscellaneous/contrastive-learning/#21-contrastive-loss","title":"2.1. Contrastive Loss","text":"<p>We suppose that we have a pair (\\(I_i\\), \\(I_j\\)) and a label \\(Y\\) that is equal to 0 if the samples are similar and 1 otherwise. To extract a low-dimensional representation of each sample, we use a Convolutional Neural Network \\(f\\) that encodes the input images \\(I_i\\) and \\(I_j\\) into an embedding space where \\(x_i = f(I_i)\\) and \\(x_j = f(I_j)\\). The contrastive loss is defined as:  </p> \\[\\mathbf{L = (1-Y) * ||x_i - x_j||^2 + Y * max(0, m - ||x_i - x_j||^2)}\\] <p>where \\(m\\) is a hyperparameter, defining lower bound distance between dissimilar samples. This can be thought of as :  </p> <ul> <li>If \\(Y = 0\\), then samples are similar and hence, we want to minimize the distance between \\(\\mathbf{x_i}\\) and \\(\\mathbf{x_j}\\).  </li> <li>If \\(Y = 1\\), then samples are dissimilar and minimizing \\(\\mathbf{L}\\) means we want to make the term \\(m - ||x_i - x_j||^2\\) \\(\\leq\\) 0. Thus, we want the distance between \\(\\mathbf{x_i}\\) and \\(\\mathbf{x_j}\\) to be maximized and greater than the lower bound \\(m\\).</li> <li>[NOTE :] This is not a classification task. We are trying to learn the embedding \\(\\mathbf{x_i}\\) for the \\(i\\)-th sample.</li> </ul>"},{"location":"Notes/Miscellaneous/contrastive-learning/#22-triplet-loss","title":"2.2. Triplet Loss","text":"<p>It takes triplet as input : an anchor sample \\(I\\), a positive sample \\(I^{+}\\) and a negative sample \\(I^{-}\\). During training, the loss function enforces the distance between anchor and positive sample to be less than the distance between anchor and negative sample.</p> <p>The triplet loss is defined as:</p> \\[\\mathbf{L = max(0, ||x - x^{+}||^2 - ||x - x^{-}||^2 + m)}\\] <p>where \\(m\\) is a hyperparameter defined in contrastive loss. Here also, we want dissimilar to be far and similar to be close so that the term \\(||x - x^{+}||^2 - ||x - x^{-}||^2 + m\\) \\(\\leq\\) 0.</p>"},{"location":"Notes/Miscellaneous/contrastive-learning/#3-types-of-learning","title":"3. Types of Learning","text":""},{"location":"Notes/Miscellaneous/contrastive-learning/#31-self-supervised-learning","title":"3.1. Self-Supervised Learning","text":"<p>When we don't have labeled samples, we use unsupervised learning, also known as self-supervised learning.</p> <p>A famous self-supervised framework for unsupervised contrastive learning is SimCLR. Its main idea is to generate positive image pairs by applying random transformations in the anchor image like crop, flip and color jitter since these changes keep the label of the image unchanged.</p>"},{"location":"Notes/Miscellaneous/contrastive-learning/#32-supervised-learning","title":"3.2. Supervised Learning","text":"<p>The label of each sample is available during training. So, we can generate positive and negative pairs or triplets by just looking at the labels. </p> <p>Positive Pairs : Samples with same label Negative Pairs : Samples with different label</p> <p>However, generating all possible pairs or triplets requires a lot of time and computational resources. Also, in every dataset, there are many negative pairs or triplets that already satisfy the contrastive training objectives and give zero loss resulting in slow training convergence.</p> <p>To deal with this problem, we have to generate hard pairs and hard triplets, meaning that their loss value is high, i.e., similar pairs that are far apart and dissimilar pairs that are very close. </p> <p>Many hard negative mining methods have been proposed that usually look into the representation space for hard pairs and triplets using fast search algorithms.</p> <pre><code>It only makes sense that this kind of contrastive learning will be used mostly\nwith self-supervised (unsupervised) or semi-supervised settings.\n</code></pre>"},{"location":"Notes/Miscellaneous/contrastive-learning/#4-related-discussion","title":"4. Related Discussion","text":"<ol> <li>Different types of Learning in Machine Learning setting is covered in this post Types of Learning.</li> </ol>"},{"location":"Notes/Miscellaneous/in-context-learning/","title":"In-context Learning (ICL)","text":"","tags":["ICL"]},{"location":"Notes/Miscellaneous/in-context-learning/#1-definition","title":"1. Definition","text":"<p>In-context Learning or ICL was defined in \"Language Models are few-shot learners\" by Brown et al., the paper that introduced GPT-3. The authors define ICL as:</p> <p>During unsupervised pre-training, a language model develops a broad set of skills and pattern recognition abilities. It then uses these abilities at inference time to rapidly adapt to or recognize the desired task. We use the term \u201cin-context learning\u201d to describe the inner loop of this process, which occurs within the forward-pass upon each sequence.</p>","tags":["ICL"]},{"location":"Notes/Miscellaneous/in-context-learning/#2-icl-vs-size-of-the-model","title":"2. ICL vs Size of the Model","text":"<p>Aky\u00fcrek et al. make another observation that ICL exhibits algorithmic phase transitions as model depth increases:</p> <ul> <li>One-layer transformers\u2019 ICL behavior approximates a single step of gradient descent, while wider and deeper transformers match ordinary least squares or ridge regression solutions.</li> <li>It is possible to imagine that if small models implement simple learning algorithms in-context, larger models might implement more sophisticated functions during ICL.</li> <li>Smaller models do not seem to learn from in-context examples, and larger ones do.</li> </ul>","tags":["ICL"]},{"location":"Notes/Miscellaneous/in-context-learning/#3-related-discussion","title":"3. Related Discussion","text":"<ol> <li>In ICL over Graphs : PRODIGY, I covered the paper \"PRODIGY : Enabling in-context learning over graphs\" which extends the concept of ICL to graphs.</li> <li>In ICL over Graphs : GraphPrompt, I covered the paper \"GraphPrompt : Unifying Pre-Training and Downstream Tasks for GNN\" which extends the concept of ICL to graphs.</li> </ol>","tags":["ICL"]},{"location":"Notes/Miscellaneous/types-of-learning/","title":"Types of Learning","text":"<p>There are broadly 3 different types of learning in Machine Learning paradigm:</p> <ul> <li>Supervised Learning</li> <li>Unsupervised Learning</li> <li>Semi-supervised Learning</li> </ul>","tags":["Basics"]},{"location":"Notes/Miscellaneous/types-of-learning/#1-supervised-learning","title":"1. Supervised Learning","text":"","tags":["Basics"]},{"location":"Notes/Miscellaneous/types-of-learning/#2-unsupervised-learning","title":"2. Unsupervised Learning","text":"","tags":["Basics"]},{"location":"Notes/Miscellaneous/types-of-learning/#3-semi-supervised-learning","title":"3. Semi-supervised Learning","text":"<p>When we have a few labeled samples and a lot of unlabeled samples, we want to be able to use both of them to optimize the performance and learning capability of our model. This is the definition of Semi-supervised Learning.</p>","tags":["Basics"]},{"location":"Python/","title":"Python-Stuff","text":""},{"location":"Python/#1-overview","title":"1. Overview","text":"<p>This section will contain sub-sections of python libraries which are used for the implementation of the code.</p>"},{"location":"Python/#2-structure","title":"2. Structure","text":"<p>The sub-sections (e.x. Pytorch, or Numpy) will have posts which will cover either of the following :</p> <ul> <li>Functions : This will cover functions of the library which are tricky to use and understand. This will also cover the functions which are not used frequently but are useful. I will cover examples of my own by running and testing them so as to understand the working and test the edge cases of the function.</li> <li>Methods : This will cover methods, i.e., an ensemble of functions. Most of the code will be standard and we should try to adhere to the best practices instead of writing the code from the scratch. Hence, I will store the code snippets for common tasks in Machine Learning which are used frequently.</li> </ul>"},{"location":"Python/#3-tags","title":"3. Tags","text":"<p>From the above structure, it is clear that the posts will be divided into two categories :</p> <ul> <li>Function</li> <li>Method</li> </ul>"},{"location":"Techie_Tech/","title":"Techie Tech","text":""},{"location":"Techie_Tech/#1-overview","title":"1. Overview","text":"<p>In case it's not clear, Techie Tech is a wordplay on Richie Rich.</p> <p>This section will contain notes on various technologies, tools, and tricks which were helpful for me and in case I need to refer to them again, I can just come here and look them up ;)</p>"},{"location":"Techie_Tech/#2-structure","title":"2. Structure","text":"<p>This section will only contain notes and no sub sections. The notes will be tagged with the technology, tool, or trick they are related to.</p> <p>Alternative Name for this section: Random in Fun as it will contain random things which I found fun to learn.  </p>"},{"location":"Techie_Tech/#3-tags","title":"3. Tags","text":"<p>I will make a list of tags which were used for this section. Whatever thing I had in my mind, I can easily look up the tags to check whether I already covered it or not.</p> <p>Following are the tags which were used in this section:</p> <ul> <li>Markdown</li> </ul>"},{"location":"Techie_Tech/markdown-things/","title":"Some Markdown Things","text":"","tags":["Markdown"]},{"location":"Techie_Tech/markdown-things/#1","title":"1.","text":"","tags":["Markdown"]}]}